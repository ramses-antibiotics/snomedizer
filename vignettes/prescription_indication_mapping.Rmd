---
title: "Mapping SNOMED CT concepts from free text"
date: '`r format(Sys.Date(), "%d %B %Y")`'
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 2
    fig_caption: yes 
    df_print: tibble
bibliography: ../inst/REFERENCES.bib
csl: the-open-university-numeric.csl
vignette: >
  %\VignetteIndexEntry{Mapping SNOMED CT concepts from free text}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(snomedizer)
data("drug_indications")
options(dplyr.summarise.inform = FALSE)
```


# Introduction

Analysing electronic health records often requires processing free-text data generated by clinicians' interactions with a variety of clinical systems. Manually classifying and coding free-text data on a large scale is impractical. 

This vignette demonstrates a rudimentary workflow to *annotate* clinical free text, that is, to extract SNOMED CT concepts from free-text information and use the full SNOMED CT ontology to reclassify these concepts into higher-level ones.

This workflow is a very simplified implementation of a technique known as *text classification*, which is very commonly employed in biomedical research. You can learn more about the wider topic from the following resources:

* [primer on natural language processing](https://www.oreilly.com/library/view/practical-natural-language/9781492054047/ch01.html) [@vajjala2020]
* [literature review](https://doi.org/10.2196/24594) of the use of SNOMED CT in the classification of free text in medicine [@gaudet2021]
* [introduction to text processing and analysis in R](https://m-clark.github.io/text-analysis-with-R/) [@clark2018] 
* [measuring text similarity using R](http://text2vec.org/similarity.html) [@selivanov2018].


# Motivating example

Healthcare providers commonly carry out clinical audits of inappropriate antibiotic prescribing. This involves measuring what antibiotics are prescribed for, and whether the dose/duration of prescriptions is suitable. Most clinical systems record prescription indications as free text.

To analyse antibiotic prescription indications, SNOMED CT concepts must extracted from the free text and grouped into categories (for instance: respiratory tract infection, urinary tract infection, etc.).

We examine an example dataset named `drug_indications` from a hospital electronic prescription system, containing free-text indications for `r nrow(drug_indications)` prescriptions.

```{r glimpse_indications}
library(snomedizer)
str(drug_indications)
```
In this vignette, we aim to identify the proportion of prescribing by type of infection.

# Preparation

## Setup

We rely on several packages from the [`tidyverse`](https://www.tidyverse.org/learn/) [@Wickham2019] to help manipulate structured data as well as string data (free text).

```{r load_packages, message=FALSE, warning=FALSE}
library(dplyr)       # relational data wrangling package 
library(tidyr)       # tidy data
library(stringr)     # to manipulate strings (free-text data) 
library(stopwords)   # lists common and uncharacteristic words to discard
library(text2vec)    # natural language processing
```

We connect to the July 2021 release branch on the official IHTSDO Snowstorm server.

```{r setup_snowstorm_server, eval = FALSE}
# Public SNOMED CT terminology server and branch
sct_server <- "https://snowstorm.ihtsdotools.org/snowstorm/snomed-ct"
sct_branch <- "MAIN/2021-07-31"

# Verify that the server connection is working
snomed_endpoint_test(sct_server, sct_branch)
#> [1] TRUE

snomedizer_options_set(endpoint = sct_server, 
                       branch = sct_branch, 
                       limit = 10000)
```

<div class="bd-callout bd-callout-warning">
<h4>SNOMED CT Licence</h4>
<p>This vignette uses SNOMED CT data under the <emph>SNOMED CT Browser License Agreement</emph>.</p>
<p>Terms and conditions can be found on <code>help("snomedizer")</code>.</p>
</div>


## Fetching concepts and descriptions

The first step is to fetch all SNOMED CT concepts that are relevant to the analysis (terminology domain). This vignette about antibiotic prescriptions is primarily interested in infectious diseases. The concepts of interest descend from the following SNOMED CT concepts:

- `40733004 | Infectious disease (disorder) |`  
- `473130003 | Suspected infectious disease (situation) |`, for syndromes that have yet to be diagnosed
- additional syndromes that are believed to be infections, but not explicitly recorded as such. For example, doctors will commonly use the concept <code>233604007 | Pneumonia (disorder) |</code> in notes and prescribe an antibacterial. In this instance we can infer they imply <code>312342009 | Infective pneumonia (disorder) |</code> or even <code>53084003 | Bacterial pneumonia (disorder) |</code>, which unlike <code>233604007</code> are descendants of  <code>40733004 | Infectious disease (disorder) | </code>

We query the terminology server in three steps: (1) retrieving descendants of the three concepts listed above; (2) combining them into a single data frame using <code>dplyr::bind_rows()</code>; and (3) retrieving descriptions (concept terms) of every concept:

```{r fetch_infection_concepts_DONTRUN, eval=FALSE, include=TRUE}
# (1) Fetch concepts descending from 40733004, 128045006, or 128477000
snomed_concepts <- concepts_descendants(
  conceptIds = c("40733004 | Infectious disease (disorder) |",
                 "128139000 | Inflammatory disorder (disorder) |",
                 "128477000 | Abscess (disorder) |")
)

# (2) Combine
snomed_concepts <- bind_rows(snomed_concepts) %>% unique()

# (3) Fetch all descriptions and collapse into single data frame
snomed_descriptions <-  concepts_descriptions(
  conceptIds = snomed_concepts$conceptId
) %>% 
  bind_rows()
```

```{r fetch_infection_concepts_RUN, include=FALSE}
snomed_descriptions <- snomedizer:::abx_indications_descriptions
snomed_concepts <- snomedizer:::abx_indications_concepts
```


`snomed_concepts` contains `r formatC(nrow(snomed_concepts), big.mark = ",")` concepts, with a total `r formatC(nrow(snomed_descriptions), big.mark = ",")` descriptions. Each concept has a minimum of 2 description records per concept: 1 fully specified name (FSN), and at least 1 (preferred) synonym. Some concepts will have more synonyms.

```{r glimpse_concepts}
snomed_concepts %>% 
  select(conceptId, active, pt.term, total) %>% 
  glimpse()

snomed_descriptions %>% 
  select(conceptId, descriptionId, term, active, type, 
         acceptabilityMap.900000000000509007, total) %>% 
  glimpse()
```


# Pre-processing

To identify SNOMED CT concepts in the free-text indications, we need to pre-process both SNOMED CT descriptions and the free text. This includes *tokenisation*, which involves separating individual words (or 'tokens') making up a character string into a vector.

The present section performs the following steps in term

1. simplify and tokenise the SNOMED CT descriptions
2. clean typos, replace acronyms, and tokenise in the free-text drug indication data.

## Processing SNOMED CT description strings

To make use of concept descriptions, we need to isolate and stardardise words making up the terminology. Only active synonyms are used (FSNs being redundant). After trimming punctuation, synonym descriptions are converted to lowercase.

```{r clean_snomed_descriptions}
tokens_snomed <- snomed_descriptions %>% 
  filter(active & type != "FSN") %>%
  select(conceptId, descriptionId, term) %>%
  mutate(text_processed = tolower(term))

snomed_cleaning_patterns <- matrix(c(
    "[(]disorder[)]",                                     "",
    "[(]disease[)]",                                      "",
    "septicaemia",                                        "sepsis",
    "septicemia",                                         "sepsis",
    "bacteremia",                                         "sepsis",
    "bacteraemia",                                        "sepsis",
    "post procedure",                                     "post_procedure",
    "post operative",                                     "post_procedure",
    "postprocedure",                                      "post_procedure",
    "postoperative",                                      "post_procedure",
    "community[-\\s]acquired",                            "community_acquired",
    "hospital[-\\s]acquired",                             "hospital_acquired",
    "institution(ally)?[-\\s]acquired",                   "institution_acquired",
    "guinea-worm",                                        "guinea worm",
    "(initial|extensive|active)([[:blank:]])(stage)",     "\\1_\\3",
    "\\bstage ([0-5])",                                   "stage_\\1",
    "intra-abdominal|intraabdominal",                     "abdominal",
    "(\\w)'s\\b",                                         "\\1",
    "[(),.]",                                             "",
    "-",                                                  " "
), ncol=2, byrow = TRUE)
colnames(snomed_cleaning_patterns) <- c(
  "pattern",
  "replacement"
)

for(i in seq_len(nrow(snomed_cleaning_patterns))) {
  tokens_snomed$text_processed <- gsub(
    snomed_cleaning_patterns[i, 1],
    snomed_cleaning_patterns[i, 2],
    tokens_snomed$text_processed,
    perl = TRUE
  )
}

```

The range of tokens is examined to identify **stop words**, that is, common words that can be eliminated, for instance prepositions. Stop words must be eliminated because they are not essential or characteristic components of a clinical term and thus make it more difficult to effectively map terminology. We also eliminate the words `"caused"` and `"due"`.


```{r tokenise_snomed_descriptions}
tokens_snomed <- transmute(
  tokens_snomed,
  conceptId,
  descriptionId,
  token_raw = stringr::str_split(text_processed, pattern = " ")
) %>%
  unnest(cols = "token_raw") %>% 
  filter(!token_raw %in% stopwords::stopwords(language = "en")) %>% 
  filter(!token_raw %in% c("", " ", ".", "_", "+", "caused", 
                           "due", "infection", "infected")) %>% 
  unique()

tokens_snomed %>% 
  group_by(token_raw) %>% 
  summarise(n = n()) %>% 
  arrange(-n) %>% 
  head(30)
```


The data frame is then condensed to have one row per `descriptionId` once again. It is now ready to be used.

```{r condense_snomed_descriptions}
tokens_snomed <- tokens_snomed %>%
  group_by(conceptId, descriptionId) %>%
  summarise(text_processed = paste(token_raw, collapse = " "))

glimpse(tokens_snomed)
```


## Processing antibiotic prescription indication strings


The `drug_indications` dataset contains free text that was manually inputted by clinicians. Due to this, it requires more extensive cleaning than SNOMED CT concept descriptions. A new variable `indication_string` is generated for conversion to lowercase, punctuation cleaning and removal of add hoc concepts. This is particularly the case with information that does not map to SNOMED CT concepts, which must be extracted manually. In this case, prescriptions issued according to advice provided by a microbiologist are often marked with short formulae such as `"as per micro"` or `"d/w micro"` (discussed with microbiology).


```{r clean_drug_indications}
drug_indications$text_processed <- tolower(drug_indications$indication)

indication_cleaning_patterns <- matrix(c(
    "(as per )(dr [a-z]*|micro advice|micro spr on call|sensitivities|micro consultant|micro)", "",
    "d/w micro", "",
    "micro approved", "",
    "(\\w)([']s)",                            "\\1",
    "[?();./,]",                              " ",
    "[[:blank:]]{2,}",                        " ",
    "other please type here",                 "",
    "bacteremia",                             "sepsis",
    "bacteraemia",                            "sepsis",
    
    # Microorganisms
    "\\bgram neg(ative)?\\b",                 "gram-negative",
    "\\bgram pos(itive)?\\b",                 "gram-positive",
    "\\bg ?-ive\\b",                          "gram-negative",
    "\\bg ?+ive\\b",                          "gram-positive",
    "g+ve cocci bc",                          "gram-positive cocci bacteremia",
    "staph a\\b",                             "staphylococcus aureus",
    "s aureus",                               "staphylococcus aureus",
    "\\bstaph\\b",                            "staphylococcus",
    "s aurea",                                "scopulariopsis aurea",
    "\\bgbs\\b|group b streptococcus|group b strep", "streptococcus agalactiae",
    "strep",                                  "streptococcus",
    "e coli|e-coli",                          "escherichia coli",
    "c[.[:blank:]]?diff(icile)?|\\bcdi\\b",   "clostridioides difficile",
    "\\bcdi\\b",                              "clostridioides difficile",
    "e faecalis",                             "enterococcus faecalis",
    "mssa",                                   "methicillin sensitive staphylococcus aureus",
    "mrsa",                                   "methicillin resistant staphylococcus aureus",
    "pseudomomonas",                          "pseudomonas",
    
    # Acronyms
    "\\buti\\b|\\buit\\b",                    "urinary tract infection",
    "craniocervical",                         "cranial cervical",
    "\\bae\\b",                               "acute exacerbation",
    "\\babx\\b",                              "antibiotic",
    "xcopd",                                  "exacerbation copd",
    "\\bcap\\b",                              "community_acquired pneumonia",
    "\\bhap\\b",                              "hospital_acquired pneumonia",
    "msu",                                    "mid stream urine",
    "\\bgnr\\b",                              "gram-negative rods",
    "\\bhsv2?\\b",                            "herpes simplex virus",
    "\\bvzv\\b",                              "varicella zoster virus",
    "esbl",                                   "extended spectrum beta-lactamase",
    
    # Others
    "post procedure",                         "post_procedure",
    "postprocedure",                          "post_procedure",
    "popst operative|post procedure",         "post_procedure",
    "\\bpostop\\b|post \\bop\\b",             "post_procedure",
    "psot \\bop\\b|post-op|post surgical",    "post_procedure",
    "quinsey",                                "quinsy",
    "infected bilioma",                       "biliary infection",
    "enteropathy",                            "intestinal infection",
    "conjunctivits",                          "conjunctivitis",
    "\\babdo\\b",                             "abdominal",
    "pnuemonia|pneumoniae|pnemonia",          "pneumonia",
    "urosepsis",                              "sepsis due to urinary tract infection",
    "\\sepssis\\b",                           "sepsis",
    "antipfungal|anti-fungal",                "antifungal",
    "abscesses",                              "abscess",
    "appendectomy-|appendicetomy|appendicectomy", "appendectomy",
    "appendiciits",                           "appendicitis",
    "aquired",                                "acquired",
    "hospital acquired",                      "hospital_acquired",
    "community acquired",                     "community_acquired",
    "celluitis|cellultis",                    "cellulitis",
    "collitis",                               "colitis",
    "\\bseporrhoeic\\b",                      "seborrhoeic",
    "broncheictasis",                         "bronchiectasis",
    "\\binfn\\b",                             "infection",
    "tonsilitis|tonsilllitis|tonsilllits",    "tonsillitis",
    "pyelonephr\\b",                          "pyelonephritis",
    "unnknown",                               "unknown",
    "crcl",                                   "creatinine clearance",
    "encocarditis",                           "endocarditis",
    "\\bcf\\b",                               "cystic fibrosis",
    "\\bpid\\b",                              "pelvic inflammatory disease",
    "dearrhoea",                              "diarrhea",
    "\\bnpenia\\b|\\bneut\\b|neutropenic|neutroepnic|nuetropenic", "neutropenic",
    "iecpod",                                 "infective exacerbation copd",
    "ipf",                                    "idiopathic pulmonary fibrosis",
    "intra[[:blank:]-]?abdominal|intrabdominal",      "abdominal",
    "infectino|infection:|infeectio",         "infection",
    "inflcted",                               "infected",
    "inplant",                                "implant",
    "\\biud\\b",                              "intrauterine device",
    "\\blrti\\b",                             "lower respiratory tract infection",
    "cadidiasis",                             "candidiasis",
    "calitis",                                "colitis",
    "peri-chondritis",                        "perichondritis",
    "non[-[:blank:]]neutropenic",             "",
    "rectovesico",                            "rectovesical",
    "recieved",                               "received",
    "cultrure|cultures",                      "culture",
    "abration",                               "abrasion",
    "folliculitiis",                          "folliculitis",
    "\\bsbp\\b",                              "spontaneous bacterial peritonitis",
    "\\bproph\\b",                            "prophylaxis",
    "supraglottits",                          "supraglottitis"
  ), ncol=2, byrow = TRUE)
colnames(indication_cleaning_patterns) <- c(
  "pattern",
  "replacement"
)

for(i in seq_len(nrow(indication_cleaning_patterns))) {
  drug_indications$text_processed <- gsub(
    indication_cleaning_patterns[i, 1],
    indication_cleaning_patterns[i, 2],
    drug_indications$text_processed,
    perl = TRUE
  )
}


tokens_prescriptions <- drug_indications %>% 
  distinct(prescription_id, indication, text_processed) %>% 
  mutate(
    token_raw = stringr::str_split(text_processed, pattern = " |[.]")
  ) %>% 
  unnest(cols = token_raw) %>% 
  filter(!token_raw %in% stopwords::stopwords(language = "en")) %>% 
  filter(!token_raw %in% c("", " ", ".", "_", "+", 
                           "infection", "infected")) %>% 
  unique()

tokens_prescriptions %>% 
  group_by(token_raw) %>% 
  summarise(n = n()) %>% 
  arrange(-n) %>% 
  head(30)
```

```{r condense_drug_indications}
tokens_prescriptions <- tokens_prescriptions %>%
  group_by(prescription_id, indication) %>%
  summarise(text_processed = paste(token_raw, collapse = " "))

glimpse(tokens_prescriptions)
```

# Text classification

In this section, we are ready to map SNOMED CT concepts in the free text. We do this by:

1. comparing tokens present in the drug indication data with tokens present in every SNOMED CT description using a similarity metric
2. setting a similarity threshold above which a SNOMED CT concept is considered to match the free text
3. using the SNOMED CT ontology to also map the free text to parents of matching concepts

## Similarity of free text with SNOMED CT descriptions

Free-text drug indications and SNOMED CT descriptions are treated as *documents*. We use the `tex2vec` library to compute the cosine distance between these documents. This requires building document-term matrices referencing which tokens occur in each document. Because some tokens are very rare or are interchangeable, we use an efficient technique known as vocabulary-based vectorisation.

```{r doc_term_matrices}
tokens_snomed_it <- itoken(tokens_snomed$text_processed, progressbar = FALSE)
tokens_prescriptions_it <- itoken(tokens_prescriptions$text_processed, progressbar = FALSE)
vectorizer_snomed <- vocab_vectorizer(create_vocabulary(tokens_snomed_it))

doc_term_snomed <- create_dtm(tokens_snomed_it, vectorizer_snomed)
rownames(doc_term_snomed) <- tokens_snomed$descriptionId
doc_term_prescriptions <- create_dtm(tokens_prescriptions_it, vectorizer_snomed)
rownames(doc_term_prescriptions) <- tokens_prescriptions$prescription_id
```

We can now compute the pairwise similarity between descriptions and prescription indications.

```{r compute_similarity, echo=TRUE}
cos_sim <- sim2(
  doc_term_snomed, 
  doc_term_prescriptions,
  method = "cosine", 
  norm = "l2"
) %>%
  as.matrix %>% 
  data.frame() %>% 
  mutate(descriptionId = row.names(.)) %>% 
  pivot_longer(starts_with("X"), 
               names_to = "prescription_id",
               names_prefix = "X",
               values_to = "similarity")  

sim_description_level <- cos_sim %>% 
  mutate(prescription_id = as.integer(prescription_id)) %>% 
  left_join(tokens_prescriptions, by = "prescription_id") %>% 
  left_join(transmute(snomed_descriptions, conceptId, descriptionId, term_synonym = term), by = "descriptionId") %>% 
  left_join(select(snomed_concepts, conceptId, term_concept = pt.term), by = "conceptId") %>% 
  arrange(prescription_id, desc(similarity))

glimpse(sim_description_level)
```

To obtain a map at the level of SNOMED CT concepts rather than SNOMED CT descriptions, we compute the maximum similarity found per concept.

```{r aggregate_similarity_concept, echo=TRUE}
sim_concept_level <- sim_description_level %>% 
  group_by(prescription_id, text_processed, conceptId, term_concept) %>% 
  summarise(max_similarity = max(similarity)) %>% 
  arrange(prescription_id, desc(max_similarity))
```

## Setting a threshold

We now wish to extract the map of concepts to free text. This involves a trade-off between:

* increasing the number of indications correctly mapped to a concept
* minimising the number of indications wrongly mapped to a concept.

This is normally done by manually reviewing a sample of the data and labelling each pair of concept and prescription indication as a true or false match.

In this instance, we will more simply show a sensitivity analysis comparing two thresholds. 
```{r map_concepts }
map_concepts_07 <- sim_concept_level %>% filter(max_similarity >= .7)
map_concepts_08 <- sim_concept_level %>% filter(max_similarity >= .8)
mapped_concepts <- c(
  "threshold0.7" = mean(tokens_prescriptions$prescription_id %in%
                          map_concepts_07$prescription_id),
  "threshold0.8" = mean(tokens_prescriptions$prescription_id %in%
                          map_concepts_08$prescription_id)
)
mapped_concepts
```

This shows `r round(mapped_concepts$threshold0.7*100)`% of drug prescriptions are mapped to a SNOMED CT concept with a threshold of 0.7, compared to `r round(mapped_concepts$threshold0.8*100)`% with a threshold of 0.8.

While it may be tempting to use the threshold of 0.7, but examination of the data reveals this may be too generous a threshold: 

```{r map_concepts_sensitivity}
map_concepts_07 %>% #ungroup %>%  
  dplyr::filter(prescription_id == 56) %>% 
  dplyr::select(text_processed, term_concept, max_similarity)
map_concepts_08 %>% #ungroup %>%  
  dplyr::filter(prescription_id == 56) %>% 
  dplyr::select(text_processed, term_concept, max_similarity)
```

This pipeline is very rudimentary, and therefore imperfect. Not all prescriptions are mapped successfully.

```{r map_concepts_missing}
tokens_prescriptions %>% ungroup %>%  
  dplyr::filter(!prescription_id %in% map_concepts_08$prescription_id) %>% 
  distinct(indication)
```

## Adding parents concepts

```{r}
# mapped_concepts_parents <- concepts_ascendants(
#   concept_ids = unique(map_concepts_08$conceptId)
# )
 
```




# Analysis and results



<!-- # Further remarks -->

<!-- <div class="bd-callout bd-callout-info"> -->

<!-- <h4>Note</h4> -->

<!-- <p>Antibiotics can also be prescribed for:</p> -->
<!-- <ul> -->
<!-- <li><strong>medical prophylaxis</strong>, to prevent a urinary tract infection. This procedure can be described with a more complex <i>postcoordinated</i> SNOMED CT expression: -->

<!-- <pre><code>281789004 |Antibiotic therapy (procedure)|: -->
<!-- { 363703001 |Has intent (attribute)| = 360271000 |Prophylaxis - procedure intent (qualifier value)|, -->
<!--   363702006 |Has focus (attribute)|  = 68566005 |Urinary tract infectious disease (disorder)| }</code></pre> -->

<!-- </li> -->
<!-- <li><strong>surgical prophylaxis</strong>, to prevent a surgical site infection that could occur as part of a <code>362958002 | Procedure by site (procedure) |</code>, for instance: -->

<!-- <pre><code>281789004 |Antibiotic therapy (procedure)|:  -->
<!-- { 363703001 |Has intent (attribute)| = 360271000 |Prophylaxis - procedure intent (qualifier value)|,   -->
<!--   363702006 |Has focus (attribute)|  = 179750003 | Incision of soft tissue of hand (procedure) | }</code></pre> -->

<!-- </li> -->
<!-- </ul> -->

<!-- <p>This contrasts with infection treatment, where  -->
<!-- <pre><code>363703001 |Has intent (attribute)| = 373808002 | Curative - procedure intent (qualifier value) |</code></pre> -->
<!-- </p> -->
<!-- <p>For simplicity, we ignore prophylactic use or SNOMED CT expressions in this vignette.</p> -->
<!-- <p>You can learn more about postcoordinated SNOMED CT expressions in the <a href="https://confluence.ihtsdotools.org/display/DOCSTART/7.+SNOMED+CT+Expressions">SNOMED CT Starter Guide (chapter 7)</a>.</p> -->

<!-- </div> -->


# References

```{css, echo=FALSE }

body {
  font-family: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";
  line-height: 1.4em;
  font-size: 16px
}

.bd-callout {
  padding: 1.5em;
  margin-top: 2em;
  margin-bottom: 2em;
  border: 1px solid #eee;
  border-left-width: .25rem;
  border-radius: .25rem;
}

.bd-callout h4, h3 {
  padding-top: 0;
  margin-top: 0;
  margin-bottom: .25rem;
}
 
.bd-callout p:last-child {
  margin-bottom: 0;
}

.bd-callout code {
  border-radius: .25rem;
}

.bd-callout + .bd-callout {
  margin-top: -.25rem;
}

.bd-callout-info {
  border-left-color: #5bc0de;
}

.bd-callout-warning {
  border-left-color: #f0ad4e;
}


.bd-callout-danger {
  border-left-color: #d9534f;
}

.bd-examples .img-thumbnail {
  margin-bottom: .75rem;
}

.bd-examples h4 {
  margin-bottom: .25rem;
}

.bd-examples p {
  margin-bottom: 1.25rem;
}
```
